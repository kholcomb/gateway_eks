---
apiVersion: eksctl.io/v1alpha5
kind: ClusterConfig

metadata:
  name: ${EKS_CLUSTER_NAME:-litellm-eks}
  region: ${AWS_REGION:-us-east-1}
  version: "1.34"
  tags:
    Environment: ${ENVIRONMENT:-production}
    Project: litellm
    ManagedBy: eksctl

# IAM OIDC Provider for service accounts
iam:
  withOIDC: true
  serviceAccounts:
    # External Secrets Operator service account
    - metadata:
        name: external-secrets
        namespace: external-secrets
      wellKnownPolicies:
        externalSecretsOperator: false  # We'll use custom policy
      attachPolicyARNs:
        - arn:aws:iam::aws:policy/AmazonSSMReadOnlyAccess
      attachPolicy:
        Version: "2012-10-17"
        Statement:
          - Effect: Allow
            Action:
              - secretsmanager:GetSecretValue
              - secretsmanager:DescribeSecret
            Resource: "arn:aws:secretsmanager:${AWS_REGION:-us-east-1}:*:secret:litellm/*"

    # LiteLLM service account for Bedrock access
    - metadata:
        name: litellm-sa
        namespace: litellm
      wellKnownPolicies:
        awsLoadBalancerController: false
      attachPolicy:
        Version: "2012-10-17"
        Statement:
          - Effect: Allow
            Action:
              - bedrock:InvokeModel
              - bedrock:InvokeModelWithResponseStream
            Resource: "*"

# VPC Configuration
# Option 1: Let eksctl create a new VPC (default)
vpc:
  cidr: 10.0.0.0/16
  clusterEndpoints:
    privateAccess: true
    publicAccess: false
  nat:
    gateway: HighlyAvailable  # Multiple NAT gateways for HA

# Option 2: Use existing VPC (uncomment and configure if you have existing VPC)
# vpc:
#   id: "vpc-xxxxx"
#   cidr: "10.0.0.0/16"
#   subnets:
#     private:
#       us-east-1a:
#         id: "subnet-xxxxx"
#       us-east-1b:
#         id: "subnet-xxxxx"
#       us-east-1c:
#         id: "subnet-xxxxx"
#     public:
#       us-east-1a:
#         id: "subnet-xxxxx"
#       us-east-1b:
#         id: "subnet-xxxxx"
#       us-east-1c:
#         id: "subnet-xxxxx"

# Managed Node Groups
managedNodeGroups:
  - name: litellm-ng-1
    instanceType: t3.medium
    minSize: 2
    maxSize: 6
    desiredCapacity: 3
    volumeSize: 100
    volumeType: gp3
    privateNetworking: true

    # Labels for pod scheduling
    labels:
      role: worker
      workload: litellm

    # Tags for AWS resources
    tags:
      Name: litellm-eks-node
      Environment: ${ENVIRONMENT:-production}
      NodeGroup: litellm-ng-1

    # Enable IMDSv2 for security
    iam:
      withAddonPolicies:
        imageBuilder: true
        autoScaler: true
        cloudWatch: true
        ebs: true
        efs: true
        albIngress: false
        xRay: false

    # Security
    ssh:
      allow: false  # SSM is preferred

    # Spot instances for cost optimization (optional)
    # instancesDistribution:
    #   maxPrice: 0.20
    #   instanceTypes: ["t3.xlarge", "t3a.xlarge", "t2.xlarge"]
    #   onDemandBaseCapacity: 1
    #   onDemandPercentageAboveBaseCapacity: 30
    #   spotInstancePools: 3

# CloudWatch Logging
cloudWatch:
  clusterLogging:
    enableTypes:
      - audit
      - authenticator
      - controllerManager
      - scheduler
      - api

# Addons
addons:
  - name: vpc-cni
    version: latest
    attachPolicyARNs:
      - arn:aws:iam::aws:policy/AmazonEKS_CNI_Policy

  - name: coredns
    version: latest

  - name: kube-proxy
    version: latest

  - name: aws-ebs-csi-driver
    version: latest
    wellKnownPolicies:
      ebsCSIController: true

# Enable kubectl access from current IAM principal
# This automatically configures aws-auth ConfigMap
#iamIdentityMappings:
#  - arn: arn:aws:iam::${AWS_ACCOUNT_ID}:root
#    groups:
#      - system:masters
#    username: admin
#    noDuplicateARNs: true

# Security and monitoring
# privateCluster:
#   enabled: false
#   skipEndpointCreation: false

# Git sync for GitOps (optional)
# gitops:
#   flux:
#     gitProvider: github
#     owner: your-org
#     repository: your-repo
#     branch: main
#     namespace: flux-system
#     path: clusters/litellm

# Fargate profiles (optional - for serverless workloads)
# fargateProfiles:
#   - name: litellm-fargate
#     selectors:
#       - namespace: fargate-workloads
