# LiteLLM Helm Chart Values
# Helm chart: oci://ghcr.io/berriai/litellm-helm

replicaCount: 2

image:
  repository: ghcr.io/berriai/litellm
  pullPolicy: IfNotPresent
  tag: "v1.80.5-stable"  # Pin to specific version for stability

# Service Account with IRSA for Bedrock access
serviceAccount:
  create: true
  name: litellm-sa
  annotations:
    # TODO: Replace with your actual IAM role ARN
    eks.amazonaws.com/role-arn: "arn:aws:iam::ACCOUNT_ID:role/litellm-bedrock-role"

# Environment variables from secrets and configmaps
env:
  # Database connection (from ExternalSecret)
  - name: DATABASE_URL
    valueFrom:
      secretKeyRef:
        name: litellm-secrets
        key: database-url

  # LiteLLM Master Key (from ExternalSecret)
  - name: LITELLM_MASTER_KEY
    valueFrom:
      secretKeyRef:
        name: litellm-secrets
        key: master-key

  # Redis configuration (using DandyDeveloper redis-ha chart)
  - name: REDIS_HOST
    value: "redis-redis-ha.litellm.svc.cluster.local"
  - name: REDIS_PORT
    value: "6379"
  - name: REDIS_PASSWORD
    valueFrom:
      secretKeyRef:
        name: redis-credentials
        key: redis-password

  # Salt key for secure hashing (cannot be changed after deployment)
  - name: LITELLM_SALT_KEY
    valueFrom:
      secretKeyRef:
        name: litellm-secrets
        key: salt-key

  # AWS Region for Bedrock (boto3 will use IRSA for credentials)
  - name: AWS_DEFAULT_REGION
    value: "us-east-1"  # TODO: Change to your region

  # OpenTelemetry configuration for Jaeger
  - name: OTEL_EXPORTER_OTLP_ENDPOINT
    value: "http://jaeger-collector.monitoring.svc.cluster.local:4318"
  - name: OTEL_EXPORTER_OTLP_PROTOCOL
    value: "http/protobuf"
  - name: OTEL_SERVICE_NAME
    value: "litellm-proxy"

# LiteLLM proxy configuration
# This gets mounted as config.yaml
config:
  model_list:
    # Claude 3.5 Sonnet - Best for complex tasks
    - model_name: claude-3.5-sonnet
      litellm_params:
        model: bedrock/anthropic.claude-3-5-sonnet-20241022-v2:0
        max_tokens: 8192

    # Claude 3 Sonnet - Good balance of speed and capability
    - model_name: claude-3-sonnet
      litellm_params:
        model: bedrock/anthropic.claude-3-sonnet-20240229-v1:0
        max_tokens: 4096

    # Claude 3 Haiku - Fastest, for simple tasks
    - model_name: claude-3-haiku
      litellm_params:
        model: bedrock/anthropic.claude-3-haiku-20240307-v1:0
        max_tokens: 4096

    # Claude 3 Opus - Most capable
    - model_name: claude-3-opus
      litellm_params:
        model: bedrock/anthropic.claude-3-opus-20240229-v1:0
        max_tokens: 4096

    # Llama 3.1 70B - Open source alternative
    - model_name: llama-3.1-70b
      litellm_params:
        model: bedrock/meta.llama3-1-70b-instruct-v1:0
        max_tokens: 2048

    # Llama 3.1 8B - Smaller, faster
    - model_name: llama-3.1-8b
      litellm_params:
        model: bedrock/meta.llama3-1-8b-instruct-v1:0
        max_tokens: 2048

    # Mistral Large
    - model_name: mistral-large
      litellm_params:
        model: bedrock/mistral.mistral-large-2407-v1:0
        max_tokens: 4096

  # Router settings for load balancing and distributed rate limiting
  router_settings:
    # Redis for distributed rate limiting across instances
    redis_host: "redis-redis-ha.litellm.svc.cluster.local"
    redis_password: "os.environ/REDIS_PASSWORD"
    redis_port: 6379
    routing_strategy: "simple-shuffle"
    num_retries: 3
    timeout: 120
    retry_after: 5

  # LiteLLM settings
  litellm_settings:
    # Enable Prometheus metrics and OpenTelemetry tracing
    callbacks: ["prometheus", "otel"]
    success_callback: ["prometheus", "otel"]
    failure_callback: ["prometheus", "otel"]

    # Request/response logging
    set_verbose: false

    # Cache settings (uses Redis)
    cache: true
    cache_params:
      type: "redis"
      host: "redis-redis-ha.litellm.svc.cluster.local"
      port: 6379
      password: "os.environ/REDIS_PASSWORD"
      ttl: 3600

    # OpenTelemetry configuration
    otel: true
    service_name: "litellm-proxy"

  # General proxy settings
  general_settings:
    master_key: "os.environ/LITELLM_MASTER_KEY"
    database_url: "os.environ/DATABASE_URL"

    # Enable proxy features
    enable_jwt_auth: false

    # Request limits
    max_request_size_mb: 50

# Resource limits
resources:
  requests:
    cpu: "500m"
    memory: "512Mi"
  limits:
    cpu: "2000m"
    memory: "2Gi"

# Liveness and readiness probes
livenessProbe:
  httpGet:
    path: /health/liveliness
    port: 4000
  initialDelaySeconds: 30
  periodSeconds: 10
  failureThreshold: 3

readinessProbe:
  httpGet:
    path: /health/readiness
    port: 4000
  initialDelaySeconds: 10
  periodSeconds: 5
  failureThreshold: 3

# Service configuration
service:
  type: ClusterIP
  port: 4000

# ServiceMonitor for Prometheus scraping
serviceMonitor:
  enabled: true
  namespace: monitoring
  interval: 30s
  path: /metrics
  labels:
    release: kube-prometheus  # Must match Prometheus selector

# Pod disruption budget for high availability
podDisruptionBudget:
  enabled: true
  minAvailable: 1

# Anti-affinity to spread pods across nodes
affinity:
  podAntiAffinity:
    preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 100
        podAffinityTerm:
          labelSelector:
            matchExpressions:
              - key: app.kubernetes.io/name
                operator: In
                values:
                  - litellm
          topologyKey: kubernetes.io/hostname
